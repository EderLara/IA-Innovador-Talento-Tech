{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMGLYWUDKU3f6sVTWvncisM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EderLara/IA-Innovador-Talento-Tech/blob/main/Ejemplo_de_Redes_generativas_adversariales_(GAN)_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ¿Qué son las Redes Generativas Adversariales (GANs)?\n",
        "\n",
        "Imagina que tienes dos entidades: un Falsificador (el Generador) y un Detective (el Discriminador).\n",
        "\n",
        "1. El Generador (G): Su trabajo es crear \"falsificaciones\" (datos sintéticos) que se parezcan lo más posible a los datos reales. Empieza creando cosas al azar, pero con el tiempo aprende a hacer falsificaciones cada vez mejores. Por ejemplo, si queremos generar imágenes de gatos, el Generador intentará crear imágenes que parezcan gatos reales. Su entrada es un vector de ruido aleatorio (llamado espacio latente) y su salida es un dato sintético (una imagen, en nuestro ejemplo).\n",
        "2. El Discriminador (D): Su trabajo es diferenciar entre los datos reales y las \"falsificaciones\" creadas por el Generador. Recibe un dato (una imagen) y debe decidir si es real (proveniente del conjunto de datos original) o falso (creado por G). Su salida es una probabilidad (por ejemplo, 0 para falso, 1 para real).\n",
        "\n",
        "## El Juego Adversarial (El Entrenamiento):\n",
        "\n",
        "Ambos, Generador y Discriminador, son redes neuronales que aprenden y mejoran compitiendo entre sí:\n",
        "\n",
        "* El Discriminador se entrena mostrándole ejemplos reales y ejemplos falsos generados por G. Aprende a identificar las características que distinguen lo real de lo falso. Su objetivo es volverse muy bueno detectando las falsificaciones (maximizar su precisión).\n",
        "* El Generador se entrena basándose en qué tan bien logra engañar al Discriminador. Si el Discriminador detecta fácilmente sus falsificaciones, el Generador ajusta sus parámetros para crear datos sintéticos más convincentes. Su objetivo es que el Discriminador clasifique sus creaciones como reales (minimizar la capacidad del Discriminador para detectar sus falsificaciones).\n",
        "\n",
        "Este proceso se repite muchas veces. A medida que el Discriminador mejora, el Generador se ve forzado a mejorar también para poder seguir engañándolo. A su vez, un Generador mejor obliga al Discriminador a volverse aún más astuto. Eventualmente, si todo va bien, el Generador aprende a crear datos sintéticos muy realistas, casi indistinguibles de los reales."
      ],
      "metadata": {
        "id": "RjHOZd0GR3wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo Práctico Paso a Paso: Generar Dígitos Manuscritos (como los del dataset MNIST)\n",
        "\n",
        "Vamos a detallar conceptualmente los pasos para entrenar una GAN que genere imágenes de dígitos escritos a mano (0 al 9), similares a los del famoso dataset MNIST.\n",
        "\n",
        "**Objetivo:** Crear una GAN capaz de generar imágenes nuevas y realistas de 28x28 píxeles que parezcan dígitos escritos a mano.\n",
        "\n",
        "**Componentes:**\n",
        "\n",
        "1. Dataset Real: Usaremos el dataset MNIST, que contiene miles de imágenes reales de 28x28 píxeles de dígitos manuscritos (0-9). Estos son los ejemplos \"reales\".\n",
        "2. Generador (G):\n",
        "  * Entrada: Un vector de ruido aleatorio (por ejemplo, de 100 dimensiones). Este ruido es la \"semilla\" creativa.\n",
        "  * Arquitectura (Conceptual): Una red neuronal (por ejemplo, con capas densas o capas convolucionales transpuestas si es una DCGAN) que transforma el vector de ruido de 100 dimensiones en una imagen de 28x28 píxeles. Podría usar funciones de activación como ReLU o LeakyReLU en capas intermedias y una función Tanh o Sigmoid en la capa final para escalar los píxeles al rango adecuado (e.g., [-1, 1] o [0, 1]).\n",
        "  * Salida: Una imagen sintética de 28x28 píxeles.\n",
        "\n",
        "3. Discriminador (D):\n",
        "  * Entrada: Una imagen de 28x28 píxeles (puede ser real del dataset MNIST o falsa generada por G).\n",
        "  * Arquitectura (Conceptual): Una red neuronal convolucional (CNN) típica para clasificación de imágenes. Tendrá capas convolucionales (para extraer características), quizás capas de pooling, capas densas y funciones de activación (comúnmente LeakyReLU para evitar gradientes nulos).\n",
        "  * Salida: Un único número (una probabilidad entre 0 y 1) que indica la probabilidad de que la imagen de entrada sea \"real\". Se usa una función Sigmoid en la capa final.\n",
        "\n",
        "## **Proceso de Entrenamiento (Iterativo):**\n",
        "El entrenamiento se realiza por épocas (pasadas completas por el dataset) y en cada época, por lotes (batches) de datos. Para cada lote:\n",
        "\n",
        "**Paso 1: Preparar Datos**\n",
        "\n",
        "  * Toma un lote de imágenes reales del dataset MNIST (ej. 64 imágenes).\n",
        "  * Genera un lote de imágenes falsas:\n",
        "    * Crea un lote de vectores de ruido aleatorio (ej. 64 vectores de 100 dimensiones).\n",
        "    * Pasa estos vectores a través del Generador (G) para obtener 64 imágenes falsas.\n",
        "\n",
        "**Paso 2: Entrenar el Discriminador (D)**\n",
        "\n",
        "  * Objetivo: Que D aprenda a distinguir las imágenes reales de las falsas de este lote.\n",
        "  * Alimenta al Discriminador con las imágenes reales. Las etiquetas objetivo para estas imágenes son 1 (o \"real\"). Calcula la pérdida del Discriminador para estas imágenes (qué tan lejos está su predicción de 1).\n",
        "  * Alimenta al Discriminador con las imágenes falsas (generadas en el Paso 1). Las etiquetas objetivo para estas imágenes son 0 (o \"falso\"). Calcula la pérdida del Discriminador para estas imágenes (qué tan lejos está su predicción de 0).\n",
        "  * Suma las dos pérdidas (real y falsa).\n",
        "  * Calcula los gradientes de esta pérdida total con respecto a los pesos del Discriminador.\n",
        "  * Actualiza los pesos del Discriminador usando un optimizador (como Adam) para minimizar esta pérdida combinada. Importante: En este paso, los pesos del Generador NO se actualizan.\n",
        "\n",
        "**Paso 3: Entrenar el Generador (G)**\n",
        "\n",
        "  * Objetivo: Que G aprenda a generar imágenes que engañen al Discriminador (que D las clasifique como 1).\n",
        "  * Genera un nuevo lote de imágenes falsas (usando nuevos vectores de ruido y el Generador G actual).\n",
        "  * Pasa estas imágenes falsas a través del Discriminador (D). Importante: Ahora, para entrenar a G, pretendemos que estas imágenes falsas son \"reales\". Por lo tanto, las etiquetas objetivo que usamos para calcular la pérdida del Generador son 1.\n",
        "  * Calcula la pérdida del Generador: qué tan lejos está la predicción del Discriminador (para las imágenes falsas) de la etiqueta objetivo 1.\n",
        "  * Calcula los gradientes de esta pérdida con respecto a los pesos del Generador. **Importante:** *En este paso, los pesos del Discriminador se mantienen fijos (no se actualizan)*. Solo queremos saber cómo debe cambiar el Generador para engañar mejor al Discriminador actual.\n",
        "  * Actualiza los pesos del Generador usando un optimizador para minimizar su pérdida (es decir, para maximizar la probabilidad de que D clasifique sus imágenes como reales).\n",
        "\n",
        "**Paso 4: Repetir**\n",
        "\n",
        "  * Repite los Pasos 1 a 3 para el siguiente lote de datos.\n",
        "  * Continúa este proceso durante muchas épocas.\n",
        "\n",
        "**Resultado Esperado:**\n",
        "\n",
        "  * Al principio, el Generador producirá ruido sin sentido. El Discriminador aprenderá rápidamente a distinguirlo de los dígitos reales.\n",
        "  * A medida que el Generador recibe retroalimentación (a través de los gradientes del Discriminador), empezará a producir formas más coherentes que se asemejan vagamente a dígitos.\n",
        "  * El Discriminador se volverá más exigente, forzando al Generador a refinar aún más sus salidas.\n",
        "  * Después de suficiente entrenamiento, el Generador debería ser capaz de producir imágenes de dígitos manuscritos que un humano (¡y el Discriminador!) tendría dificultades para distinguir de los reales. Podrás darle un vector de ruido aleatorio y obtener una imagen nueva y única de un dígito.\n",
        "\n",
        "**Consideraciones Clave:**\n",
        "\n",
        "  * Equilibrio: Es crucial mantener un equilibrio en el entrenamiento. Si el Discriminador se vuelve demasiado bueno muy rápido, el Generador no podrá aprender. Si el Generador engaña fácilmente al Discriminador desde el principio, no recibirá gradientes útiles para mejorar.\n",
        "  * Funciones de Pérdida: Comúnmente se usa la Entropía Cruzada Binaria (Binary Cross-Entropy) tanto para el Discriminador como para el Generador.\n",
        "  * Hiperparámetros: La tasa de aprendizaje, el tamaño del lote, la arquitectura de las redes y el tamaño del vector de ruido son hiperparámetros importantes que necesitan ser ajustados.\n",
        "  * Colapso de Modos (Mode Collapse): A veces, el Generador puede aprender a producir solo un tipo o un conjunto muy limitado de salidas que engañan bien al Discriminador, en lugar de aprender toda la diversidad del dataset real. Es un desafío común en el entrenamiento de GANs.\n",
        "\n",
        "Este ejemplo pretende dar una visión general del flujo de trabajo y la lógica detrás del entrenamiento de una GAN.\n",
        "\n",
        "La implementación real implicaría usar librerías como TensorFlow o PyTorch para definir las redes neuronales y el bucle de entrenamiento."
      ],
      "metadata": {
        "id": "jBu-cDy0SVgZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*El siguiente código está diseñado para ser lo más claro posible y puedes ejecutarlo en entornos como Google Colab (que te da acceso gratuito a GPUs, lo cual es muy recomendable para entrenar GANs).*"
      ],
      "metadata": {
        "id": "otceqtQBXL16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "DCGAN Simple en Keras/TensorFlow para generar dígitos MNIST.\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os # Para guardar imágenes\n",
        "\n",
        "# --- 1. Hiperparámetros y Configuración ---\n",
        "BUFFER_SIZE = 60000                         # Tamaño del buffer para barajar el dataset (igual al tamaño de MNIST)\n",
        "BATCH_SIZE = 256                            # Tamaño del lote\n",
        "EPOCHS = 50                                 # Número de épocas de entrenamiento (puede necesitar más para mejores resultados)\n",
        "latent_dim = 100                            # Dimensión del vector de ruido de entrada para el generador\n",
        "img_rows = 28\n",
        "img_cols = 28\n",
        "channels = 1\n",
        "img_shape = (img_rows, img_cols, channels)\n",
        "\n",
        "# Optimizers - Adam es común para GANs\n",
        "# Usar beta_1=0.5 a veces ayuda a estabilizar el entrenamiento\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
        "\n",
        "# Función de Pérdida\n",
        "# Usamos BinaryCrossentropy porque el discriminador da una probabilidad (0 o 1)\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False) # False porque la última capa del D tiene Sigmoid\n",
        "\n",
        "# Directorio para guardar imágenes generadas\n",
        "if not os.path.exists('gan_images_mnist'):\n",
        "    os.makedirs('gan_images_mnist')"
      ],
      "metadata": {
        "id": "Whycsd_qXeeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Cargar y Preparar el Dataset MNIST ---\n",
        "(train_images, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Añadir dimensión de canal y normalizar las imágenes al rango [-1, 1]\n",
        "# (tanh en la salida del generador produce valores en [-1, 1])\n",
        "train_images = train_images.reshape(train_images.shape[0], img_rows, img_cols, channels).astype('float32')\n",
        "train_images = (train_images - 127.5) / 127.5\n",
        "\n",
        "# Crear lotes y barajar el dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "516NidljXgVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Construir el Generador (G) ---\n",
        "# Transforma un vector de ruido (latent_dim) en una imagen (28x28x1)\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    # Capa densa inicial y reshape para empezar a formar la imagen\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(latent_dim,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256) # None es el tamaño del batch\n",
        "\n",
        "    # Capas convolucionales transpuestas (Deconvolution) para aumentar tamaño\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    # Capa final con activación tanh para que la salida esté en [-1, 1]\n",
        "    model.add(layers.Conv2DTranspose(channels, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, img_rows, img_cols, channels)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "tjIGxzePXmVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Construir el Discriminador (D) ---\n",
        "# Clasifica una imagen (28x28x1) como real (1) o falsa (0)\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    # Capas convolucionales para extraer características\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=img_shape))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3)) # Dropout para regularización\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    # Aplanar y capa densa final con Sigmoid para probabilidad\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1, activation='sigmoid')) # Salida de probabilidad\n",
        "\n",
        "    return model\n",
        "\n",
        "# Crear instancias de los modelos\n",
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()\n",
        "\n",
        "print(\"--- Resumen del Generador ---\")\n",
        "generator.summary()\n",
        "print(\"\\n--- Resumen del Discriminador ---\")\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "id": "wvH5GjwKXpPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. Definir las Funciones de Pérdida ---\n",
        "\n",
        "# Pérdida del Discriminador: Compara predicciones en imágenes reales con un array de 1s,\n",
        "# y predicciones en imágenes falsas con un array de 0s.\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output) # Queremos que prediga 1 para reales\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output) # Queremos que prediga 0 para falsas\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "# Pérdida del Generador: Intenta engañar al discriminador.\n",
        "# Compara las predicciones del discriminador sobre imágenes falsas con un array de 1s.\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output) # Queremos que D prediga 1 para las falsas"
      ],
      "metadata": {
        "id": "R52kxW3PX0BW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 6. Definir el Paso de Entrenamiento ---\n",
        "# Usamos tf.function para compilar la función en un grafo, lo que acelera el entrenamiento.\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    # 1. Generar ruido y luego imágenes falsas\n",
        "    noise = tf.random.normal([BATCH_SIZE, latent_dim])\n",
        "\n",
        "    # Usamos GradientTape para registrar las operaciones para la diferenciación automática\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        # 2. Obtener predicciones del Discriminador\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        # 3. Calcular pérdidas\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    # 4. Calcular gradientes\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    # 5. Aplicar gradientes para actualizar pesos\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss # Devolver pérdidas para monitoreo"
      ],
      "metadata": {
        "id": "RiUSPxMYX5Xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 7. Helper para Generar y Guardar Imágenes ---\n",
        "# Usaremos un conjunto fijo de vectores de ruido para ver cómo evoluciona la generación\n",
        "seed = tf.random.normal([16, latent_dim]) # Generaremos 16 imágenes de ejemplo\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "    # `training=False` para que capas como BatchNormalization funcionen en modo inferencia.\n",
        "    predictions = model(test_input, training=False)\n",
        "    # Re-escalar de [-1, 1] a [0, 1] para mostrar/guardar\n",
        "    predictions = (predictions + 1) / 2.0\n",
        "\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        # Si es a color, usar predictions[i, :, :, :]\n",
        "        plt.imshow(predictions[i, :, :, 0] * 255.0, cmap='gray') # Multiplicar por 255 si se guarda como entero\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.savefig('gan_images_mnist/image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.show() # También mostrar en el notebook/consola si es posible"
      ],
      "metadata": {
        "id": "QZ0uLMWXX-zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 8. Bucle de Entrenamiento ---\n",
        "def train(dataset, epochs):\n",
        "    print(\"\\n--- Iniciando Entrenamiento ---\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start_time = time.time()\n",
        "        gen_loss_epoch = []\n",
        "        disc_loss_epoch = []\n",
        "\n",
        "        for image_batch in dataset:\n",
        "            g_loss, d_loss = train_step(image_batch)\n",
        "            gen_loss_epoch.append(g_loss)\n",
        "            disc_loss_epoch.append(d_loss)\n",
        "\n",
        "        # Calcular pérdidas promedio por época\n",
        "        avg_gen_loss = np.mean(gen_loss_epoch)\n",
        "        avg_disc_loss = np.mean(disc_loss_epoch)\n",
        "\n",
        "        # Producir imágenes al final de la época (o cada N épocas)\n",
        "        generate_and_save_images(generator, epoch + 1, seed)\n",
        "\n",
        "        # Imprimir progreso\n",
        "        print(f'Época {epoch + 1}/{epochs} completada en {time.time() - epoch_start_time:.2f} seg')\n",
        "        print(f'  Pérdida del Generador: {avg_gen_loss:.4f}, Pérdida del Discriminador: {avg_disc_loss:.4f}')\n",
        "\n",
        "    # Generar imágenes después del entrenamiento final\n",
        "    generate_and_save_images(generator, epochs, seed)\n",
        "    print(f'\\nEntrenamiento completado en {(time.time() - start_time)/60:.2f} minutos.')              # Utilizar el"
      ],
      "metadata": {
        "id": "ldIH43iBYDaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Iniciar el entrenamiento ---\n",
        "train(train_dataset, EPOCHS)\n",
        "\n",
        "# --- Opcional: Guardar los modelos ---\n",
        "# generator.save('generator_mnist_dcgan.h5')\n",
        "# discriminator.save('discriminator_mnist_dcgan.h5')"
      ],
      "metadata": {
        "id": "lyP1rvWmSVRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXnXID1HRign"
      },
      "outputs": [],
      "source": []
    }
  ]
}